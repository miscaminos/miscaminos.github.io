Hands on Machine Learning(chapter01)

# What is Machine Learning?

명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게 하는 연구 분야이다.

명시적인 프로그래밍 없이?

-> 어떤 문제를 풀기위해서 프로그래머가 instruction을 작성하지않고 컴퓨터가 알아서 문제를 해결하는 방식을 뜻한다. 전통적인 프로그래밍 방식은 다음과 같다.

문제연구 -> 규칙 작성 -> 평가 -> 론칭

(평가시 문제가 발생한다면 평가 -> 오차분석 -> 문제연구 -> 규칙작성 -> 다시 평가)

전통적인 프로그래밍과는 다르게 머신러닝 방식은 다음과 같다.

문제연구 -> 데이터분석 & 머신러닝 알고리즘 훈련 -> 솔루션 평가 -> 론칭 (평가시 문제가 발생한다면 평가 -> 오차분석 -> 문제연구로 돌아온다)



### ML pipeline (머신러닝 작업흐름):

흔히 말하는 DevOps, MLOps가 pipeline의 구축을 이끄는데, 

데이터 업데이트 -> 데이터분석 & 머신러닝 알고리즘 훈련 -> 솔루션 평가 -> 론칭 -> 데이터 업데이트 -> ...

이런 사이클이 자동화되어 반복된다. 지속적으로 데이터가 업데이트되어서 새로운 데이터로 알고리즘을 훈련시키고 성능이 개선된 알고리즘으로 솔루션을 평가 및 론칭하는 것이다.



### ML applications 예시:

-제품 이미지를 보고 자동으로 분류 (via CNN)

-자동으로 뉴스기사 분류/ 음성을 듣고 이해하는 앱  (via RNN, CNN 또는 transformer를 통한 NLP)

-내년도 회사의 수익을 예측 (via regression)

-구매 이력을 기반으로 고객을 나누기 (via clustering)



### ML system의 종류

훈련 방법: 지도 학습, 비지도 학습, 준지도 학습, 강화 학습

훈련 시점: 온라인 학습 / 배치 학습

모델 생성: 사례기반 학습 / 모델 기반 학습



#### 훈련 방법

1. 지도 학습

   정답이 있는 경우

   지도 학습 = 분류 or 회귀로 나누어진다.

   대표적인 지도 학습의 종류 : linear regression, logistic regression, support vector machine, decision tree, ensemble, neural network

2. 비지도 학습

   정답이 없는 경우

   대표적인 비지도 학습의 종류: k-평균, DBSCAN(Density-based Spatial Clustering of Applications with Noise), PCA(Principal Component Analysis), GMM(Gaussian Mixture Model), Autoencoder

   비지도 학습의 keywords:

   -군집: 사전 정보 없이 쌓여 있는 그룹 정보를 의미 있는 서브그룹 또는 클러스터로 조직하는 탐색적 데이터 분석 기법, 각 클러스터는 어느 정도 유사성을 공유하고 다른 클러스터와는 비슷하지 않은 샘플 그룹을 형성

   -차원축소: noise 데이터를 제거하기 위해 특성 전처리 단계에서 종종 적용하는 방법, 관련 있는 정보를 대부분 유지하면서 더 작은 차원을 가진 부분 공간으로 데이터를 압축

3. 준지도 학습

   정답이 일부만 있는 경우

   예를들어 분류가 된 그룹들 중에 어떤 그룹에 새로운 샘플이 포함되는지를 알아내는 문제해결을 위해서는 준지도 학습이 사용된다.

4. 강화 학습

   행동의 보상/벌칙이 있는 경우

   agent가 벌칙 대신 보상을 받을 수 있는 경우들을 학습시켜서 보상을 받는 경우로 학습을 유도하는 방법 

   

#### 훈련시점: 온라인 학습 vs. 배치 학습

온라인 학습: 

적은 데이터를 사용해서 점진적으로 훈련한다. 실시간 시스템이나 메모리가 부족한 경우 적합

배치 학습: 

전체 데이터를 사용해 오프라인에서 훈련한다. 컴퓨팅 자원이 풍부한 경우 적합



#### 모델 생성 방식

사례기반 학습:

sample을 기억하는 훈련방식. 예측을 위해 sample사이의 유사도를 측정한다.

모델기반 학습:

sample을 사용해서 모델을 훈련한다. 훈련된 모델을 사용해서 예측값을 구한다.



### 모델기반 학습 예제

문제: 돈이 사람을 행복하게 만드는가?

given data : 

scatter graph 1인당GDP (x-axis) vs. 삶의_만족도(y-axis)

선형 방정식으로 그래프를 표현할 수 있다.

```삶의_만족도 = c + b*(1인당GDP) ```

여기서 c,b는 모델 parameter (모델이 가지고있는 변수)



#### 충분한 데이터

간단한 문제라도 수천개의 데이터가 필요하다. 이미지나 음성 인식과 같은 문제는 수백만개가 필요할 수 있다. 데이터가 충분하지 못하다면 모델개선 effort가 헛수고가 될수도있다.



#### 대표성을 갖춘 데이터

우연에 의해 대표성이 없는 데이터를 수집하게 되는 경우, sampling noise가 있다고 한다. 표본 추출 방법이 잘못된 대표성이 없는 데이터를 sampling 편향이라 한다.



#### 좋은 품질의 데이터

이상치 sample이 있다면 고치거나 무시해야한다. 특성이 누락되었을때, 해당 특성을 제외하거나, 해당 sample을 제외하거나, 누락된 값을 대체할 수 있는 적절한 값으로 채우거나, 또는 해당 특성을 넣은 경우와 뺀 경우 각기 모델을 훈련시켜본다.



#### test data set & train data set

모델의 일반화 성능을 측정하기위해서 훈련했던 데이터가 아닌 다른 데이터 세트를 사용한다. (연습 문제로 훈련하고, 연습과는 다른 실전 문제로 학생의 실력을 평가하듯) 훈련시 사용되는 데이터는 train set, 성능을 측정하기위해 사용되는 데이터는 test set으로 나눈다. 

Hyperparameter는 알고리즘을 조절하기 위해 사전에 정의하는 parameter이다. 조절한 모델을 test하기전에 성능을 검증하기위해서 validation set도 추가적으로 확보되어야한다. 

그래서 모델 선택 및 훈련을 위해서는 train set(훈련 세트), validation set(검증 또는 개발 세트) , test set(테스트 세트)로 수집 및 처리된 데이터를 나눈다.



#### 검증 세트  vs. 테스트 세트

검증세트는 모델의 hyperparatemer를 tuning하면서 모델을 비교하고 선택하기위해 성능을 확인할때에 사용하도록 훈련세트에서 held back된 데이터이다. 모델을 비교하는데에 사용된다. 검증 세트를 사용해서 가장 좋은 모델을 고르고 hyperparameter를 tuning 한다.

선택된 final 모델의 성능을 평가하기위해서는 테스트 세트를 사용한다. 테스트 세트는 실전에 모델이 배치되기 전에 새로운 샘플에 대한 일반화 오차를 추정하기 위해 사용되는 것이다.여기에서 중요한점은 모델을 평가하기 위해서는 모델 훈련(또는 모델 tuning시 검증)으로 사용되지 않았던 데이터세트를 사용한다는 점 이다.



#### 모델 평가

과대적합: 훈련세트에 모델이 너무 잘 맞아서 일반화(generalization) 성능이 낮은 상태. 규제를 사용해서 과대적합 문제를 방지할 수 있다.

과소적합: 과대적합의 반대로, 모델이 너무 단순해서 훈련세트를 잘 학습하지 못한 상태. 과소적합 문제를 방지하기위해서는 모델 parameter가 더 많은 모델을 사용하거나/ 특성 공학으로 더 좋은 특성을 찾거나/ 규제의 강도를 줄일 수 있다.

**note**: 특성공학(feature engineering)이란? 특성 선택 또는 특성 추출을 통해서 해결하려는 문제와 관련이 높은 특성을 찾는다. 특성 선택은 준비되어있는 특성 중 가장 유용한 특성을 찾는 것이고, 특성 추출은 특성을 조합하여 새로운 특성을 만드는것이다.

훈련-개발 세트: 모델이 실전에 투입했을때 사용될 데이터와 가능한 최대로 가까워야하는 검증과 테스트에 사용되는 데이터와 훈련 데이터 사이에 데이터 불일치 위험이 있을때에 사용된다.

훈련 세트의 일부에서 모델을 훈련하고, 훈련-개발 세트와 검증 세트에서 평가한다.
모델이 훈련세트에서는 잘동작하지만, 훈련-개발 세트에서 나쁜 성능을 낸다면, 아마 훈련세트에 과대적합되있을 가능성이 높다. 

훈련세트와 훈련-개발 세트 양쪽에서 모두 잘 동작하지만, 개발세트에서 성능이 나쁘다면, 훈련데이터와 검증+테스트 데이터 사이에 데이터 불일치가 있을 가능성이 높다. 검증+테스트 데이터에 더 가깝게 되도록 훈련 데이터를 개선해야한다.

<hr>

#### reference

1. Hands on Machine Learning with Scikit-Learn, Keras, and TensorFlow second edition by Aurelien Geron, Haesun Park
2. [What is the Difference Between Test and Validation Datasets?][https://machinelearningmastery.com/difference-test-validation-datasets/]





